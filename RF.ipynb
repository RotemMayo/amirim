{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "LABEL_INDEX = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.read_hdf(\"./events_anomalydetection_v2.features.h5\")\n",
    "# data_as_tuples = list(dataset.itertuples())\n",
    "dataset = pd.concat([full_dataset[:10**5], full_dataset[-1*10**4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data = list(small_dataset.itertuples())\n",
    "# [train_data[0]] + [train_data[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1467.23999023   611.50201416   511.10198975 ...    79.81510162\n",
      "     21.01029968    16.75760078]\n",
      " [-1211.23999023   347.31500244   547.9630127  ...     8.0421896\n",
      "      6.33509016     5.52536011]\n",
      " [-1229.61999512   649.85797119     8.08917046 ...    15.29290009\n",
      "     13.94419956    10.01350021]\n",
      " ...\n",
      " [ -149.33000183  1781.45996094   -58.6908989  ...    79.12010193\n",
      "     46.53730011    23.22730064]\n",
      " [ 1584.69995117  -731.15698242  -196.3480072  ...   366.18899536\n",
      "    192.13900757    81.39820099]\n",
      " [-1229.59997559 -1009.89001465  1105.80004883 ...   238.96600342\n",
      "    130.36999512    88.14409637]]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# print(len(train_data)\n",
    "# Counter([i[-1] for i in train_data])\n",
    "x = dataset.iloc[:, 0:LABEL_INDEX].values\n",
    "y = dataset.iloc[:, LABEL_INDEX].values\n",
    "print(str(x))\n",
    "print(str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "# print(len(x_train))\n",
    "# print(len(x_test))\n",
    "# print(Counter(y_train))\n",
    "# print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  912.41497803   904.66900635  -478.95999146   214.54899597\n",
      "    159.1190033     82.74919891    62.88499832  -876.54302979\n",
      "   -880.28399658  -897.42797852   140.80700684    44.10860062\n",
      "     31.31110001    18.70639992]\n",
      " [ 1113.98999023 -1019.22998047   935.20898438   149.28399658\n",
      "     64.17189789    41.30039978    33.39789963   587.58099365\n",
      "   1086.42004395   -84.81600189   663.21899414   568.44299316\n",
      "    224.03999329   109.90899658]]\n",
      "[[ 0.90801941  0.90309745 -0.4097019  -0.02183458  0.1731204   0.55435299\n",
      "   0.85581705 -0.98818547 -0.99478724 -0.77247743 -0.44404696 -0.65827286\n",
      "  -0.47034895 -0.61041917]\n",
      " [ 1.10899263 -1.01808479  0.82055994 -0.41929821 -0.51579258 -0.28480139\n",
      "  -0.1271039   0.66414832  1.22845482 -0.07298144  2.96275329  3.40840354\n",
      "   3.64227748  2.60611955]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sc = StandardScaler()\n",
    "scaled_x_train = sc.fit_transform(x_train)\n",
    "scaled_x_test = sc.transform(x_test)\n",
    "print(x_train[0:2])\n",
    "print(scaled_x_train[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took about 20 seconds\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(scaled_x_train, y_train)\n",
    "y_pred = regressor.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000\n",
      "626\n",
      "619\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "pred_signal = [i for i in range(len(y_pred)) if y_pred[i] == 1] \n",
    "print(len(pred_signal))\n",
    "print(len([i for i in pred_signal if y_test[i] == 1]))\n",
    "# print(len([i for i in range(len(y_pred)) if y_pred[i] == y_test[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1631970461.863416\n",
      "fit 1631971456.574479\n",
      "pred 1631971458.305404\n",
      "220000\n",
      "7055\n",
      "6957\n",
      "0.9861091424521616\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nfor full_dataset:\\nstart 1624715840.3091583\\nfit 1624716328.8221645\\npred 1624716329.6628819\\n220000\\n7055\\n6957\\n0.9861091424521616\\n'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# complete regressor\n",
    "x = full_dataset.iloc[:, 0:LABEL_INDEX].values\n",
    "y = full_dataset.iloc[:, LABEL_INDEX].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "scaled_x_train = sc.fit_transform(x_train)\n",
    "scaled_x_test = sc.transform(x_test)\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "print(f\"start {time.time()}\")\n",
    "regressor.fit(scaled_x_train, y_train)\n",
    "print(f\"fit {time.time()}\")\n",
    "y_pred = regressor.predict(scaled_x_test)\n",
    "print(f\"pred {time.time()}\")\n",
    "\n",
    "\n",
    "pred_signal = [i for i in range(len(y_pred)) if y_pred[i] == 1]\n",
    "real_signal = [i for i in pred_signal if y_test[i] == 1]\n",
    "print(len(y_pred))\n",
    "print(len(pred_signal))\n",
    "print(len(real_signal))\n",
    "print(len(real_signal) / len(pred_signal))\n",
    "\"\"\"\n",
    "for full_dataset:\n",
    "start 1624715840.3091583\n",
    "fit 1624716328.8221645\n",
    "pred 1624716329.6628819\n",
    "220000\n",
    "7055\n",
    "6957\n",
    "0.9861091424521616\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.04905454545454545\n",
      "Mean Squared Error: 0.02391215909090909\n",
      "Root Mean Squared Error: 0.154635568647414\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1631971458.527349\n",
      "fitted 1631971761.809546\n",
      "predicted 1631971763.600317\n",
      "220000\n",
      "16349\n",
      "15001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# took about 20 seconds\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "print(f\"start {time.time()}\")\n",
    "classifier.fit(scaled_x_train, y_train)\n",
    "print(f\"fitted {time.time()}\")\n",
    "cls_y_pred = classifier.predict(scaled_x_test)\n",
    "print(f\"predicted {time.time()}\")\n",
    "\n",
    "print(len(cls_y_pred))\n",
    "cls_pred_signal = [i for i in range(len(cls_y_pred)) if cls_y_pred[i] == 1] \n",
    "print(len(cls_pred_signal))\n",
    "print(len([i for i in cls_pred_signal if y_test[i] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1631971763.748289\n",
      "fitted 1631971835.55857\n",
      "predicted 1631971901.029619\n",
      "total tested 1100000\n",
      "found signal 99000\n",
      "real  signal 13307\n",
      "ratio signal 0.1344141414141414\n"
     ]
    }
   ],
   "source": [
    "## Isolation Forest - 13% with not labled data\n",
    "## https://scikit-learn.org/stable/modules/outlier_detection.html\n",
    "\n",
    "# background_train_dataset = full_dataset[:10**6 - 10 ** 5].iloc[:, 0:LABEL_INDEX].values\n",
    "# background_test_dataset = full_dataset[10**6 - 10 ** 5:].iloc[:, 0:LABEL_INDEX].values # should be half signal\n",
    "# train_set = background_train_dataset\n",
    "# test_set = background_test_dataset\n",
    "# is_signal = lambda i: i > 10**5\n",
    "\n",
    "\n",
    "# x = full_dataset.iloc[:, 0:LABEL_INDEX].values\n",
    "# y = full_dataset.iloc[:, LABEL_INDEX].values\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "# train_set = x_train\n",
    "# test_set = x_test\n",
    "# is_signal = lambda i: y_test[i] == 1\n",
    "\n",
    "train_set = test_set = full_dataset.iloc[:, 0:LABEL_INDEX].values\n",
    "is_signal = lambda i: i > 10**6\n",
    "\n",
    "# x = full_dataset.iloc[:, 0:LABEL_INDEX].values\n",
    "# y = full_dataset.iloc[:, LABEL_INDEX].values\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "# train_set = test_set = x_train\n",
    "# is_signal = lambda i: y_train[i] == 1\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# scaled_train = sc.fit_transform(scaled_train)\n",
    "# scaled_test = sc.transform(scaled_test)\n",
    "\n",
    "iso_forest = IsolationForest(n_estimators=100, random_state=0, contamination=0.09)\n",
    "print(f\"start {time.time()}\")\n",
    "iso_forest.fit(train_set)\n",
    "print(f\"fitted {time.time()}\")\n",
    "iso_y_pred = iso_forest.predict(test_set)\n",
    "print(f\"predicted {time.time()}\")\n",
    "\n",
    "iso_pred_signal = [i for i in range(len(iso_y_pred)) if iso_y_pred[i] != 1]\n",
    "count_real_signal = len([i for i in iso_pred_signal if is_signal(i)])\n",
    "print(f\"total tested {len(iso_y_pred)}\")\n",
    "print(f\"found signal {len(iso_pred_signal)}\")\n",
    "print(f\"real  signal {count_real_signal}\")\n",
    "print(f\"ratio signal {count_real_signal / len(iso_pred_signal)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1211.23999023   347.31500244   547.9630127    389.53201294\n",
      "   191.80400085    99.56279755    70.87220001   619.34100342\n",
      "   -62.1772995  -1944.04003906    22.99920082     8.0421896\n",
      "     6.33509016     5.52536011]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(train_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## local outline factor - 6% (less than starting ration) with not labled data\n",
    "import os\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "train_set = test_set = full_dataset.iloc[:, 0:LABEL_INDEX].values\n",
    "is_signal = lambda i: i > 10**6\n",
    "\n",
    "# perdictor = LocalOutlierFactor(n_neighbors=35, contamination=0.09)\n",
    "perdictor = LocalOutlierFactor(n_neighbors=35, contamination=0.09, n_jobs=10)\n",
    "print(f\"start {time.time()}\")\n",
    "y_pred = perdictor.fit_predict(train_set)\n",
    "print(f\"pred {time.time()}\")\n",
    "\n",
    "pred_signal = [i for i in range(len(y_pred)) if y_pred[i] != 1]\n",
    "count_real_signal = len([i for i in pred_signal if is_signal(i)])\n",
    "real_signal = [i for i in range(len(train_set)) if is_signal(i)]\n",
    "\n",
    "print(f\"total tested {len(y_pred)}\")\n",
    "print(f\"found signal {len(pred_signal)}\")\n",
    "print(f\"real  signal {count_real_signal}\")\n",
    "print(f\"ratio signal {count_real_signal / len(pred_signal)}\")\n",
    "print(f\"recall: {count_real_signal/len(real_signal)}\")\n",
    "os.system(\"printf '\\a'\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found signal 35964\n",
      "real  signal 6780\n",
      "ratio signal 0.18852185518852185\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## local outline factor +  Isolation Forest 18% with not labled data\n",
    "\n",
    "combined_signal = list(set(iso_pred_signal) & set(pred_signal))\n",
    "count_real_signal = len([i for i in pred_signal if is_signal(i)])\n",
    "# print(f\"total tested {len(y_pred)}\")\n",
    "print(f\"found signal {len(combined_signal)}\")\n",
    "print(f\"real  signal {count_real_signal}\")\n",
    "print(f\"ratio signal {count_real_signal / len(combined_signal)}\")\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "11000\n",
      "start 1631972295.204567\n",
      "pred 1631972301.255411\n",
      "total tested 11000\n",
      "found signal 1101\n",
      "real  signal 143\n",
      "ratio signal 0.1298819255222525\n"
     ]
    }
   ],
   "source": [
    "### SVM - slow, 13% when training on background and then checking on mix\n",
    "# from here https://scikit-learn.org/stable/modules/outlier_detection.html\n",
    "# background_train_dataset = full_dataset[:10**6 - 10 ** 5].iloc[:, 0:LABEL_INDEX].values\n",
    "# test_dataset = full_dataset[10 ** 6 - 10 ** 5:10 ** 6 + 10 ** 4].iloc[:, 0:LABEL_INDEX].values\n",
    "# train_dataset = dataset.iloc[:, 0:LABEL_INDEX]\n",
    "\n",
    "## train on little data\n",
    "x = full_dataset.iloc[:, 0:LABEL_INDEX].values\n",
    "y = full_dataset.iloc[:, LABEL_INDEX].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.99, random_state=0)\n",
    "train_dataset = test_dataset = x_train\n",
    "is_signal = lambda i: y_train[i]\n",
    "\n",
    "\n",
    "## train on background only \n",
    "# N = 4\n",
    "# train_dataset = full_dataset[:10 ** N].iloc[:, 0:LABEL_INDEX].values\n",
    "# test_dataset = full_dataset[10 ** 6 - 10 ** N : 10 ** 6 + 10 ** (N - 1)].iloc[:, 0:LABEL_INDEX].values\n",
    "# is_signal = lambda i: i > 10 ** N\n",
    "\n",
    "# dataset = pd.concat([full_dataset[:10**4], full_dataset[-1*10**3:]])\n",
    "# is_signal = lambda i: i > 10**5\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "onc_class_svm = svm.OneClassSVM(nu=0.1, kernel=\"rbf\")\n",
    "print(f\"start {time.time()}\")\n",
    "# onc_class_svm.fit(train_dataset)\n",
    "# print(f\"fit {time.time()}\")\n",
    "# y_pred = onc_class_svm.predict(test_dataset)\n",
    "y_pred = onc_class_svm.fit_predict(train_dataset)\n",
    "print(f\"pred {time.time()}\")\n",
    "\n",
    "pred_signal = [i for i in range(len(y_pred)) if y_pred[i] != 1]\n",
    "count_real_signal = len([i for i in pred_signal if is_signal(i)])\n",
    "print(f\"total tested {len(y_pred)}\")\n",
    "print(f\"found signal {len(pred_signal)}\")\n",
    "print(f\"real  signal {count_real_signal}\")\n",
    "print(f\"ratio signal {count_real_signal / len(pred_signal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 1632840927.280201\n",
      "fit 1632841022.25182\n",
      "pred 1632841145.2981088\n",
      "total tested 110000\n",
      "found signal 12396\n",
      "real  signal 3653\n",
      "ratio signal 0.2946918360761536\n",
      "recall: 0.3653365336533653\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nfor n = 5\\nstart 1624726190.1007173\\nfit 1624726201.004385\\npred 1624726213.5636365\\ntotal tested 110000\\nfound signal 12396\\nreal  signal 3653\\nratio signal 0.2946918360761536\\n'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# local outline factor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "full_dataset = pd.read_hdf(\"./events_anomalydetection_v2.features.h5\")\n",
    "\n",
    "# x = full_dataset.iloc[:, 0:LABEL_INDEX].values\n",
    "# y = full_dataset.iloc[:, LABEL_INDEX].values\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.9, random_state=0)\n",
    "# train_dataset = test_dataset = x_train\n",
    "# is_signal = lambda i: y_train[i]\n",
    "\n",
    "## train on background only \n",
    "N = 5\n",
    "train_dataset = full_dataset[:10 ** N].iloc[:, 0:LABEL_INDEX].values\n",
    "test_dataset = full_dataset[10 ** 6 - 10 ** N : 10 ** 6 + 10 ** (N - 1)].iloc[:, 0:LABEL_INDEX].values\n",
    "is_signal = lambda i: i > 10 ** N\n",
    "\n",
    "\n",
    "# perdictor = LocalOutlierFactor(n_neighbors=35, contamination=0.09)\n",
    "perdictor = LocalOutlierFactor(n_neighbors=200, contamination=0.09, novelty=True, n_jobs=10)\n",
    "print(f\"start {time.time()}\")\n",
    "perdictor.fit(train_dataset)\n",
    "print(f\"fit {time.time()}\")\n",
    "y_pred = perdictor.predict(test_dataset)\n",
    "# y_pred = perdictor.fit_predict(train_dataset)\n",
    "print(f\"pred {time.time()}\")\n",
    "\n",
    "pred_signal = [i for i in range(len(y_pred)) if y_pred[i] != 1]\n",
    "count_real_signal = len([i for i in pred_signal if is_signal(i)])\n",
    "real_signal = [i for i in range(len(test_dataset)) if is_signal(i)]\n",
    "\n",
    "print(f\"total tested {len(y_pred)}\")\n",
    "print(f\"found signal {len(pred_signal)}\")\n",
    "print(f\"real  signal {count_real_signal}\")\n",
    "print(f\"ratio signal {count_real_signal / len(pred_signal)}\")\n",
    "print(f\"recall: {count_real_signal/len(real_signal)}\")\n",
    "\"\"\"\n",
    "for n = 5\n",
    "start 1624726190.1007173\n",
    "fit 1624726201.004385\n",
    "pred 1624726213.5636365\n",
    "total tested 110000\n",
    "found signal 12396\n",
    "real  signal 3653\n",
    "ratio signal 0.2946918360761536\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-8d8c002af4ca>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mumap\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mumap\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "# https://github.com/lmcinnes/umap\n",
    "import umap\n",
    "import umap.plot\n",
    "\n",
    "x = test_dataset\n",
    "y = y_pred\n",
    "mapper = umap.UMAP().fit(x)\n",
    "umap.plot.points(mapper, labels=y )\n",
    "\n",
    "# x = full_dataset[10**6-10000:10**6+1000].iloc[:, 0:LABEL_INDEX].values\n",
    "# y = full_dataset[10**6-10000:10**6+1000].iloc[:, LABEL_INDEX].values\n",
    "# mapper = umap.UMAP().fit(x)\n",
    "# umap.plot.points(mapper, labels=y )\n",
    "\n",
    "# digits = load_digits()\n",
    "# mapper = umap.UMAP().fit(digits.data)\n",
    "# umap.plot.points(mapper, labels=digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}